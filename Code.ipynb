{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (cross_val_score, train_test_split, \n",
    "                                    RepeatedStratifiedKFold, GridSearchCV)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột Age có 177 giá trị bị trông, Fare không có giá trị bị trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lặp Logistic Regression với random state của train_test_split thay đổi từ 0 đến 9 \n",
    "#### Lấy độ chính xác trung bình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_logistic_reg(data, has_new_feature=False):\n",
    "    \"\"\"\n",
    "    Hàm áp dụng Logistic Regression cho bài toán Titanic\n",
    "    data : dataset\n",
    "    has_new_feature : có tạo thêm đặc trưng mới hay không\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    for i in range(0, 10):\n",
    "        # Nếu có tạo thêm đặc trưng thì sử dung thêm cột Age_NAN\n",
    "        if has_new_feature:\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                data[['Age', 'Fare', 'Age_NAN']].fillna(0), data['Survived'],\n",
    "                test_size=0.3, random_state=i)\n",
    "        else:\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                data[['Age', 'Fare']].fillna(0), data['Survived'],\n",
    "                test_size=0.3, random_state=i)\n",
    "        # Tạo bộ phân loại và huấn luyện\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        # Kết quả dự đoán\n",
    "        Y_pred = classifier.predict(X_test)\n",
    "        # Thêm vào mảng kết quả\n",
    "        acc.append(accuracy_score(Y_test, Y_pred))\n",
    "    # Lấy trung bình\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Không xử lý gì cả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.6 (%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(use_logistic_reg(df) * 100, 1)} (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng median để thay thế dữ liệu trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_way(df):\n",
    "    data1 = df.copy()\n",
    "    median = data1['Age'].median()\n",
    "    data1['Age'] = data1['Age'].fillna(median)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng mean để thay thế dữ liệu trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_way(df):\n",
    "    data2 = df.copy()\n",
    "    mean = data2['Age'].mean()\n",
    "    data2['Age'] = data2['Age'].fillna(mean)\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng mode để thay thế dữ liệu trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_way(df):\n",
    "    data3 = df.copy()\n",
    "    mode = data3['Age'].mode()[0]\n",
    "    data3['Age'] = data3['Age'].fillna(mode)\n",
    "    return data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thay thế dữ liệu trống bằng giá trị ngẫu nhiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_way(df):\n",
    "    data4 = df.copy()\n",
    "    # Loại bỏ các giá trị trống của cột Age và lấy ra ngẫu nhiên K giá trị\n",
    "    # K là số lượng phần tử trống đã bị loại bỏ\n",
    "    random_samples = data4['Age'].dropna().sample(n=data4['Age'].isnull().sum(), random_state=0)\n",
    "    # Gán chỉ số của K giá trị ngẫu nhiên đó thành chỉ số K phân tử trống cột Age\n",
    "    random_samples.index = data4[data4['Age'].isnull()].index\n",
    "    # Thay thế K phần tử trống cột Age thành K giá trị ngẫu nhiên đã chọn\n",
    "    data4.loc[data4['Age'].isnull(), 'Age'] = random_samples\n",
    "    return data4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thay thế dữ liệu trống bằng giá trị đuôi phân bố"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_of_dist_way(df):\n",
    "    data5 = df.copy()\n",
    "    # Giá trị đuôi phân bố = mean + 3 * std\n",
    "    extreme = data5[\"Age\"].mean() + 3 * data5[\"Age\"].std()\n",
    "    data5[\"Age\"] = data5[\"Age\"].fillna(extreme)\n",
    "    return data5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thay thế dữ liệu trống bằng giá trị bất kì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbitrary_way(df, ar_age):\n",
    "    data6 = df.copy()\n",
    "    data6[\"Age\"] = data6[\"Age\"].fillna(ar_age)\n",
    "    return data6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo đặc trưng mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_feature_way(df):\n",
    "    data7 = df.copy()\n",
    "    # Tạo cột Age_NAN\n",
    "    data7['Age_NAN'] = np.where(data7['Age'].isnull(), 1, 0)\n",
    "    # Thay thế dữ liệu trống cột Age thành giá trị median\n",
    "    data7[\"Age\"].fillna(data7[\"Age\"].median(), inplace=True)\n",
    "    return data7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý ngoại lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.880374349943303 73.27860964406094\n",
      "-61.358399999999996 100.2688\n"
     ]
    }
   ],
   "source": [
    "# Age có dạng phân bố chuẩn\n",
    "# Biên dưới : mean - 3 * std   ;   Biên trên : mean + 3 * std\n",
    "upper_boundary = df['Age'].mean() + 3* df['Age'].std()\n",
    "lower_boundary = df['Age'].mean() - 3* df['Age'].std()\n",
    "print(lower_boundary, upper_boundary)\n",
    "\n",
    "# Fare có dạng phân bố lệch\n",
    "# Biên dưới : 1st Quantile - 3 * IQR   ;   Biên trên : 3rd Quantile + 3 * IQR\n",
    "IQR = df[\"Fare\"].quantile(0.75) - df[\"Fare\"].quantile(0.25)\n",
    "lower_bridge = df['Fare'].quantile(0.25) - (IQR*3)\n",
    "upper_bridge = df['Fare'].quantile(0.75) + (IQR*3)\n",
    "print(lower_bridge, upper_bridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thay thế các giá trị tuổi lớn hơn biên trên bằng 73\n",
    "\n",
    "Thay thế các giá vé lớn hơn biên trên bằng 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_outlier = df.copy()\n",
    "df_not_outlier.loc[df_not_outlier['Age'] >= 73, 'Age'] = 73\n",
    "df_not_outlier.loc[df_not_outlier['Fare'] >= 100, 'Fare'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng để thu được 14 loại dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Có Outlier\n",
    "data_median = median_way(df)\n",
    "data_mean = mean_way(df)\n",
    "data_mode = mode_way(df)\n",
    "data_random = random_way(df)\n",
    "data_endofdist = end_of_dist_way(df)\n",
    "data_arbitrary = arbitrary_way(df, ar_age=27)\n",
    "data_newfeature = new_feature_way(df)\n",
    "# Không có Outlier\n",
    "data_median_outlier = median_way(df_not_outlier)\n",
    "data_mean_outlier = mean_way(df_not_outlier)\n",
    "data_mode_outlier = mode_way(df_not_outlier)\n",
    "data_random_outlier = random_way(df_not_outlier)\n",
    "data_endofdist_outlier = end_of_dist_way(df_not_outlier)\n",
    "data_arbitrary_outlier = arbitrary_way(df_not_outlier, ar_age=27)\n",
    "data_newfeature_outlier = new_feature_way(df_not_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thống kê độ chính xác 14 cách"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Đơn vị độ chính xác : %\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|       TYPE      | Median | Mean | Mode | Random | End of Dist | Arbitrary | New feature |\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|      ORIGIN     |  65.3  | 65.3 | 65.3 |  65.4  |     66.4    |    65.4   |     66.0    |\n",
      "| OUTLIER-PROCESS |  66.7  | 66.7 | 66.6 |  66.8  |     66.7    |    66.6   |     66.3    |\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "def acc(data, has_new_feature=False):\n",
    "    # Làm tròn\n",
    "    return round(use_logistic_reg(data, has_new_feature) * 100, 1)\n",
    "\n",
    "\n",
    "table = PrettyTable([\"TYPE\",\"Median\",\"Mean\",\"Mode\",\"Random\",\n",
    "                    \"End of Dist\",\"Arbitrary\",\"New feature\"])\n",
    "\n",
    "table.add_row([\"ORIGIN\", acc(data_median), acc(data_mean), acc(data_mode), acc(data_random), \n",
    "                acc(data_endofdist), acc(data_arbitrary), acc(data_newfeature, True)])\n",
    "\n",
    "table.add_row([\"OUTLIER-PROCESS\", acc(data_median_outlier), acc(data_mean_outlier),\n",
    "                acc(data_mode_outlier), acc(data_random_outlier), acc(data_endofdist_outlier),\n",
    "                acc(data_arbitrary_outlier), acc(data_newfeature_outlier, True)])\n",
    "\n",
    "print(\">> Đơn vị độ chính xác : %\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ chính xác thấp nhất là 65.3 (%) khi không xử lý ngoại lệ với các phương pháp Median, Mean, Mode, NewFeature.\n",
    "Do 3 phương pháp Median, Mean, Mode và NewFeature(thay dữ liệu cột trống bằng Median) làm thay đổi phương sai của dữ liệu.\n",
    "\n",
    "Độ chính xác cao nhất là 66.8 (%) khi xử lý ngoại lệ và áp dụng phương pháp Random.\n",
    "Trong bài toán này thì phương pháp Random hoạt động tốt do nó làm phương sai của dữ liệu ít bị biến đổi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng chuẩn hóa (không chuẩn hóa cột Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn hóa z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def zscore_norm(data):\n",
    "    scaler = StandardScaler()\n",
    "    df_zscore = data[['Age', 'Fare']].copy()\n",
    "    df_zscore = pd.DataFrame(scaler.fit_transform(df_zscore), columns=df_zscore.columns)\n",
    "    df_zscore['Survived'] = data['Survived']\n",
    "    # Nế có cột Age_NAN thì cũng giữ nguyên\n",
    "    if 'Age_NAN' in data.columns:\n",
    "        df_zscore['Age_NAN'] = data['Age_NAN']\n",
    "    return df_zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn hóa min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def minmax_norm(data):\n",
    "    min_max = MinMaxScaler()\n",
    "    df_minmax = data[['Age', 'Fare']].copy()\n",
    "    df_minmax = pd.DataFrame(min_max.fit_transform(df_minmax), columns=df_minmax.columns)\n",
    "    df_minmax['Survived'] = data['Survived']\n",
    "    # Nế có cột Age_NAN thì cũng giữ nguyên\n",
    "    if 'Age_NAN' in data.columns:\n",
    "        df_minmax['Age_NAN'] = data['Age_NAN']\n",
    "    return df_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn hóa mạnh với ngoại lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def robust_norm(data):\n",
    "    scaler = RobustScaler()\n",
    "    df_robust = data[['Age', 'Fare']].copy()\n",
    "    df_robust = pd.DataFrame(scaler.fit_transform(df_robust), columns=df_robust.columns)\n",
    "    df_robust['Survived'] = data['Survived']\n",
    "    # Nế có cột Age_NAN thì cũng giữ nguyên\n",
    "    if 'Age_NAN' in data.columns:\n",
    "        df_robust['Age_NAN'] = data['Age_NAN']\n",
    "    return df_robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thống kê độ chính xác khi áp dụng chuẩn hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng chuẩn hóa cho các tổ hợp có xử lý outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Đơn vị độ chính xác : %\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|   TYPE  | Median | Mean | Mode | Random | End of Dist | Arbitrary | New feature |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "| z-score |  66.6  | 66.6 | 66.6 |  66.8  |     66.7    |    66.6   |     66.3    |\n",
      "| min-max |  66.9  | 67.0 | 66.9 |  66.9  |     66.5    |    66.8   |     66.2    |\n",
      "|  robust |  66.6  | 66.7 | 66.6 |  66.8  |     66.7    |    66.6   |     66.3    |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable([\"TYPE\", \"Median\", \"Mean\", \"Mode\", \"Random\",\n",
    "                    \"End of Dist\", \"Arbitrary\", \"New feature\"])\n",
    "table.add_row([\"z-score\", acc(zscore_norm(data_median_outlier)),\n",
    "                acc(zscore_norm(data_mean_outlier)),\n",
    "                acc(zscore_norm(data_mode_outlier)),\n",
    "                acc(zscore_norm(data_random_outlier)),\n",
    "                acc(zscore_norm(data_endofdist_outlier)),\n",
    "                acc(zscore_norm(data_arbitrary_outlier)),\n",
    "                acc(zscore_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "table.add_row([\"min-max\", acc(minmax_norm(data_median_outlier)),\n",
    "               acc(minmax_norm(data_mean_outlier)),\n",
    "               acc(minmax_norm(data_mode_outlier)),\n",
    "               acc(minmax_norm(data_random_outlier)),\n",
    "               acc(minmax_norm(data_endofdist_outlier)),\n",
    "               acc(minmax_norm(data_arbitrary_outlier)),\n",
    "               acc(minmax_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "table.add_row([\"robust\", acc(robust_norm(data_median_outlier)),\n",
    "               acc(robust_norm(data_mean_outlier)),\n",
    "               acc(robust_norm(data_mode_outlier)),\n",
    "               acc(robust_norm(data_random_outlier)),\n",
    "               acc(robust_norm(data_endofdist_outlier)),\n",
    "               acc(robust_norm(data_arbitrary_outlier)),\n",
    "               acc(robust_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "print(\">> Đơn vị độ chính xác : %\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng chuẩn hóa Min-Max cho tổ hợp có xử lý outlier và xử lý dữ liệu trống\\\n",
    "thu được độ chính xác cao nhất là 67 (%) ở phương pháp Mean (tăng từ 66,7 (%) lên 67 (%))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_logistic_cross_val(data, has_new_feature=False):\n",
    "    \"\"\"\n",
    "    Hàm áp dụng Logistic Regression cho bài toán Titanic\n",
    "    Chia dữ liệu bằng Cross Validation\n",
    "    data : dataset\n",
    "    has_new_feature : có tạo thêm đặc trưng mới hay không\n",
    "    \"\"\"\n",
    "    lr = LogisticRegression()\n",
    "    # Nếu có tạo thêm đặc trưng thì sử dung thêm cột Age_NAN\n",
    "    if has_new_feature:\n",
    "        X = data[['Age', 'Fare', 'Age_NAN']].fillna(0)\n",
    "    else:\n",
    "        X = data[['Age', 'Fare']].fillna(0)\n",
    "    Y = data['Survived']\n",
    "    # Thực hiện Cross-Validation\n",
    "    scores = cross_val_score(lr, X, Y, cv=5)\n",
    "    # Lấy trung bình độ chính xác 5 folds\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng Cross-Validation cho 14 tổ hợp làm sạch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Đơn vị độ chính xác : %\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|       TYPE      | Median | Mean | Mode | Random | End of Dist | Arbitrary | New feature |\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|      ORIGIN     |  66.0  | 65.9 | 66.2 |  66.9  |     66.8    |    66.1   |     66.2    |\n",
      "| OUTLIER-PROCESS |  67.2  | 67.2 | 67.5 |  67.1  |     67.0    |    67.0   |     66.5    |\n",
      "+-----------------+--------+------+------+--------+-------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "def acc(data, has_new_feature=False):\n",
    "    # Làm tròn\n",
    "    return round(use_logistic_cross_val(data, has_new_feature) * 100, 1)\n",
    "\n",
    "\n",
    "table = PrettyTable([\"TYPE\", \"Median\", \"Mean\", \"Mode\", \"Random\",\n",
    "                    \"End of Dist\", \"Arbitrary\", \"New feature\"])\n",
    "\n",
    "table.add_row([\"ORIGIN\", acc(data_median), acc(data_mean), acc(data_mode), acc(data_random),\n",
    "               acc(data_endofdist), acc(data_arbitrary), acc(data_newfeature, True)])\n",
    "\n",
    "table.add_row([\"OUTLIER-PROCESS\", acc(data_median_outlier), acc(data_mean_outlier),\n",
    "               acc(data_mode_outlier), acc(data_random_outlier), acc(data_endofdist_outlier),\n",
    "               acc(data_arbitrary_outlier), acc(data_newfeature_outlier, True)])\n",
    "\n",
    "print(\">> Đơn vị độ chính xác : %\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ chính xác cao nhất 67,5 (%) thuộc về trường hợp xử lý trống bằng Mode và có xử lý ngoại lệ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng thêm chuẩn hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Đơn vị độ chính xác : %\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|   TYPE  | Median | Mean | Mode | Random | End of Dist | Arbitrary | New feature |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "| z-score |  67.1  | 67.1 | 67.5 |  67.2  |     67.0    |    67.1   |     66.6    |\n",
      "| min-max |  67.1  | 67.2 | 67.5 |  67.6  |     66.6    |    67.1   |     66.7    |\n",
      "|  robust |  67.1  | 67.1 | 67.5 |  67.2  |     67.0    |    67.1   |     66.6    |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable([\"TYPE\", \"Median\", \"Mean\", \"Mode\", \"Random\",\n",
    "                    \"End of Dist\", \"Arbitrary\", \"New feature\"])\n",
    "table.add_row([\"z-score\", acc(zscore_norm(data_median_outlier)),\n",
    "                acc(zscore_norm(data_mean_outlier)),\n",
    "                acc(zscore_norm(data_mode_outlier)),\n",
    "                acc(zscore_norm(data_random_outlier)),\n",
    "                acc(zscore_norm(data_endofdist_outlier)),\n",
    "                acc(zscore_norm(data_arbitrary_outlier)),\n",
    "                acc(zscore_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "table.add_row([\"min-max\", acc(minmax_norm(data_median_outlier)),\n",
    "               acc(minmax_norm(data_mean_outlier)),\n",
    "               acc(minmax_norm(data_mode_outlier)),\n",
    "               acc(minmax_norm(data_random_outlier)),\n",
    "               acc(minmax_norm(data_endofdist_outlier)),\n",
    "               acc(minmax_norm(data_arbitrary_outlier)),\n",
    "               acc(minmax_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "table.add_row([\"robust\", acc(robust_norm(data_median_outlier)),\n",
    "               acc(robust_norm(data_mean_outlier)),\n",
    "               acc(robust_norm(data_mode_outlier)),\n",
    "               acc(robust_norm(data_random_outlier)),\n",
    "               acc(robust_norm(data_endofdist_outlier)),\n",
    "               acc(robust_norm(data_arbitrary_outlier)),\n",
    "               acc(robust_norm(data_newfeature_outlier), True)])\n",
    "\n",
    "print(\">> Đơn vị độ chính xác : %\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi áp dụng chuẩn hóa thì độ chính xác cao nhất là 67.6 (%) ở phương pháp Random, có xử lý ngoại lệ và chuẩn hóa min-max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_hyper_tuning(data, has_new_feature=False):\n",
    "    # Nếu có tạo thêm đặc trưng thì sử dung thêm cột Age_NAN\n",
    "    if has_new_feature:\n",
    "        X = data[['Age', 'Fare', 'Age_NAN']].fillna(0)\n",
    "    else:\n",
    "        X = data[['Age', 'Fare']].fillna(0)\n",
    "    Y = data['Survived']\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    # solver = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "    # penalty = [\"l1\", \"l2\", \"elasticnet\", \"none\"]\n",
    "\n",
    "    grid = {\n",
    "        \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        \"penalty\": ['l2'],\n",
    "        \"C\": [100, 10, 1.0, 0.1, 0.01]\n",
    "    }\n",
    "    \"\"\"\n",
    "    Tạo Grid Search với các tham số : \n",
    "    estimator : thuật toán đánh giá\n",
    "    param_grid : danh sách các siêu tham số dùng đánh giá mô hình\n",
    "    n_jobs : dùng -1 để dùng toàn bộ nhân xử lý của Máy tính cho tác vụ này\n",
    "    cv : Số lượng Fold trong Cross-Validation\n",
    "    scoring : tiêu chí đánh giá\n",
    "    error_score : kết quả trả về khi áp dụng 1 phương pháp mà xảy ra lỗi\n",
    "    \"\"\"\n",
    "    grid = GridSearchCV(estimator=lr, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy', error_score=0)\n",
    "    result = grid.fit(X, Y)\n",
    "    \n",
    "    # Kết quả Tuning tốt nhất\n",
    "    print(f\">> Best: {result.best_score_} using {result.best_params_}\")\n",
    "    # In ra kết quả toàn bộ các phương pháp dùng Tuning\n",
    "    means = result.cv_results_[\"mean_test_score\"]\n",
    "    stds = result.cv_results_[\"std_test_score\"]\n",
    "    params = result.cv_results_[\"params\"]\n",
    "    table = PrettyTable([\"C\", \"penalty\", \"solver\", \"std\", \"mean\"])\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        table.add_row([param[\"C\"], param[\"penalty\"], param[\"solver\"], std, mean])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Best: 0.6757579561860523 using {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "+------+---------+-----------+----------------------+--------------------+\n",
      "|  C   | penalty |   solver  |         std          |        mean        |\n",
      "+------+---------+-----------+----------------------+--------------------+\n",
      "| 100  |    l2   | newton-cg | 0.057695787956962126 | 0.6712824053731719 |\n",
      "| 100  |    l2   |   lbfgs   | 0.057695787956962126 | 0.6712824053731719 |\n",
      "| 100  |    l2   | liblinear | 0.057695787956962126 | 0.6712824053731719 |\n",
      "|  10  |    l2   | newton-cg | 0.05823068722558555  | 0.6724060008787898 |\n",
      "|  10  |    l2   |   lbfgs   | 0.05823068722558555  | 0.6724060008787898 |\n",
      "|  10  |    l2   | liblinear | 0.05823068722558555  | 0.6724060008787898 |\n",
      "| 1.0  |    l2   | newton-cg | 0.051825010901695064 | 0.6757579561860523 |\n",
      "| 1.0  |    l2   |   lbfgs   | 0.051825010901695064 | 0.6757579561860523 |\n",
      "| 1.0  |    l2   | liblinear | 0.05092623337927883  | 0.6746343606804344 |\n",
      "| 0.1  |    l2   | newton-cg | 0.03576197372142431  | 0.6689849978030256 |\n",
      "| 0.1  |    l2   |   lbfgs   | 0.03576197372142431  | 0.6689849978030256 |\n",
      "| 0.1  |    l2   | liblinear | 0.03539552479576416  | 0.6678551252275438 |\n",
      "| 0.01 |    l2   | newton-cg | 0.002324923639127706 | 0.6161634548992531 |\n",
      "| 0.01 |    l2   |   lbfgs   | 0.002324923639127706 | 0.6161634548992531 |\n",
      "| 0.01 |    l2   | liblinear | 0.002324923639127706 | 0.6161634548992531 |\n",
      "+------+---------+-----------+----------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "logistic_hyper_tuning(minmax_norm(data_random_outlier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kết quả cao nhất là 0.6757 ~ 67,6 (%) và xuất hiện ở các trường hợp : \n",
    "{'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'} (mặc định)\\\n",
    "{'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng các siêu tham số này cho toàn bộ dữ liệu để thu được mô hình tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.6 (%)\n"
     ]
    }
   ],
   "source": [
    "X = data_random_outlier[['Age', 'Fare']]\n",
    "Y = data_random_outlier['Survived']\n",
    "# Tạo bộ phân loại và huấn luyện\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X, Y)\n",
    "Y_pred = classifier.predict(X)\n",
    "print(f\"{round(accuracy_score(Y, Y_pred)*100, 1)} (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thêm đặc trưng giới tính để đua Top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode giới tính bằng LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def sex_encode(data):\n",
    "    data_top = data.copy()\n",
    "    le = LabelEncoder()\n",
    "    data_top[\"Sex\"] = df[\"Sex\"]\n",
    "    le.fit(data_top[\"Sex\"])\n",
    "    data_top[\"Sex_Encode\"] = le.transform(data_top[\"Sex\"])\n",
    "    return data_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo lại Logistic Regression với Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_logistic_data_top(data, has_new_feature=False):\n",
    "    \"\"\"\n",
    "    Hàm áp dụng Logistic Regression cho bài toán Titanic\n",
    "    Chia dữ liệu bằng Cross Validation\n",
    "    data : dataset\n",
    "    has_new_feature : có tạo thêm đặc trưng mới hay không\n",
    "    \"\"\"\n",
    "    lr = LogisticRegression()\n",
    "    # Nếu có tạo thêm đặc trưng thì sử dung thêm cột Age_NAN\n",
    "    if has_new_feature:\n",
    "        X = data[['Age', 'Fare', 'Age_NAN', \"Sex_Encode\"]].fillna(0)\n",
    "    else:\n",
    "        X = data[['Age', 'Fare', \"Sex_Encode\"]].fillna(0)\n",
    "    Y = data['Survived']\n",
    "\n",
    "    # Tạo 5-folds cross-validation lặp 3 lần để tăng hiệu quả\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # Thực hiện Cross-Validation\n",
    "    scores = cross_val_score(lr, X, Y, cv=cv)\n",
    "    # Lấy trung bình độ chính xác 5 folds\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá các tổ hợp đã xử lý outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Đơn vị độ chính xác : %\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "|   TYPE  | Median | Mean | Mode | Random | End of Dist | Arbitrary | New feature |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n",
      "| z-score |  78.5  | 78.5 | 78.5 |  78.4  |     78.6    |    78.5   |     78.6    |\n",
      "| min-max |  78.3  | 78.3 | 78.3 |  78.6  |     78.6    |    78.3   |     78.6    |\n",
      "|  robust |  78.5  | 78.5 | 78.5 |  78.4  |     78.6    |    78.5   |     78.6    |\n",
      "+---------+--------+------+------+--------+-------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "def acc(data, has_new_feature=False):\n",
    "    # Làm tròn\n",
    "    return round(use_logistic_data_top(data, has_new_feature) * 100, 1)\n",
    "\n",
    "table = PrettyTable([\"TYPE\", \"Median\", \"Mean\", \"Mode\", \"Random\",\n",
    "                    \"End of Dist\", \"Arbitrary\", \"New feature\"])\n",
    "table.add_row([\"z-score\", acc(sex_encode(zscore_norm(data_median_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_mean_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_mode_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_random_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_endofdist_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_arbitrary_outlier))),\n",
    "               acc(sex_encode(zscore_norm(data_newfeature_outlier)), True)])\n",
    "\n",
    "table.add_row([\"min-max\", acc(sex_encode(minmax_norm(data_median_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_mean_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_mode_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_random_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_endofdist_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_arbitrary_outlier))),\n",
    "               acc(sex_encode(minmax_norm(data_newfeature_outlier)), True)])\n",
    "\n",
    "table.add_row([\"robust\", acc(sex_encode(robust_norm(data_median_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_mean_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_mode_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_random_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_endofdist_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_arbitrary_outlier))),\n",
    "               acc(sex_encode(robust_norm(data_newfeature_outlier)), True)])\n",
    "\n",
    "print(\">> Đơn vị độ chính xác : %\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả cao nhất là 78,6 (%) xảy ra cả 3 trường hợp chuẩn hóa của phương pháp EndOfDist và New Feature và ở chuẩn hóa min-max cho phương pháp Random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypermeter tuning cho dữ liệu khi xét thêm giới tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_tuning_data_top(data, has_new_feature=False):\n",
    "    # Nếu có tạo thêm đặc trưng thì sử dung thêm cột Age_NAN\n",
    "    if has_new_feature:\n",
    "        X = data[['Age', 'Fare', 'Age_NAN', \"Sex_Encode\"]].fillna(0)\n",
    "    else:\n",
    "        X = data[['Age', 'Fare', \"Sex_Encode\"]].fillna(0)\n",
    "    Y = data['Survived']\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # solver = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "    # penalty = [\"l1\", \"l2\", \"elasticnet\", \"none\"]\n",
    "\n",
    "    grid = {\n",
    "        \"solver\": ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        \"penalty\": ['l2'],\n",
    "        \"C\": [100, 10, 1.0, 0.1, 0.01]\n",
    "    }\n",
    "    \n",
    "    # Tạo 5-folds cross-validation lặp 3 lần để tăng hiệu quả\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=lr, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "    result = grid.fit(X, Y)\n",
    "\n",
    "    # Kết quả Tuning tốt nhất\n",
    "    print(f\">> Best: {result.best_score_} using {result.best_params_}\")\n",
    "    # In ra kết quả toàn bộ các phương pháp dùng Tuning\n",
    "    means = result.cv_results_[\"mean_test_score\"]\n",
    "    stds = result.cv_results_[\"std_test_score\"]\n",
    "    params = result.cv_results_[\"params\"]\n",
    "    table = PrettyTable([\"C\", \"penalty\", \"solver\", \"std\", \"mean\"])\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        table.add_row([param[\"C\"], param[\"penalty\"], param[\"solver\"], std, mean])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning cho trường hợp Random-MinMax-Có xử lý outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Best: 0.7867574749440295 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "+------+---------+-----------+----------------------+--------------------+\n",
      "|  C   | penalty |   solver  |         std          |        mean        |\n",
      "+------+---------+-----------+----------------------+--------------------+\n",
      "| 100  |    l2   | newton-cg | 0.020689615430597316 | 0.7833887807837967 |\n",
      "| 100  |    l2   |   lbfgs   | 0.020689615430597316 | 0.7833887807837967 |\n",
      "| 100  |    l2   | liblinear | 0.020689615430597316 | 0.7833887807837967 |\n",
      "|  10  |    l2   | newton-cg | 0.020068078685305017 | 0.7841378444542088 |\n",
      "|  10  |    l2   |   lbfgs   | 0.020068078685305017 | 0.7841378444542088 |\n",
      "|  10  |    l2   | liblinear | 0.020068078685305017 | 0.7841378444542088 |\n",
      "| 1.0  |    l2   | newton-cg | 0.01873746348193569  | 0.785629694725169  |\n",
      "| 1.0  |    l2   |   lbfgs   | 0.01873746348193569  | 0.785629694725169  |\n",
      "| 1.0  |    l2   | liblinear |  0.0191513304390025  | 0.7845060992195508 |\n",
      "| 0.1  |    l2   | newton-cg | 0.01985289664644779  | 0.7867574749440295 |\n",
      "| 0.1  |    l2   |   lbfgs   | 0.01985289664644779  | 0.7867574749440295 |\n",
      "| 0.1  |    l2   | liblinear | 0.01985289664644779  | 0.7867574749440295 |\n",
      "| 0.01 |    l2   | newton-cg | 0.014987847693202298 | 0.6906053187705313 |\n",
      "| 0.01 |    l2   |   lbfgs   | 0.014987847693202298 | 0.6906053187705313 |\n",
      "| 0.01 |    l2   | liblinear | 0.019275548034178837 | 0.7037076559328772 |\n",
      "+------+---------+-----------+----------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "logistic_tuning_data_top(sex_encode(minmax_norm(data_random_outlier)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thu được độ chính xác 0.7867 ~ 78.7 (%) cao hơn trường hợp dùng bộ tham số mặc định 78,6 (%) ở các bộ siêu tham số :\n",
    "{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\\\n",
    "{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\\\n",
    "{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kết quả tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.7 (%)\n"
     ]
    }
   ],
   "source": [
    "best_data = sex_encode(minmax_norm(data_random_outlier))\n",
    "lr = LogisticRegression(C=0.1)\n",
    "# Tạo 5-folds cross-validation lặp 3 lần để tăng hiệu quả\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "# Thực hiện Cross-Validation\n",
    "scores = cross_val_score(lr, best_data[[\"Age\",\"Fare\",\"Sex_Encode\"]], Y, cv=cv)\n",
    "# Lấy trung bình độ chính xác 5 folds\n",
    "print(f\"{round(np.mean(scores)*100, 1)} (%)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
